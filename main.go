/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"context"
	"errors"
	"flag"
	"fmt"
	"os"
	"time"

	"github.com/darkowlzz/operator-toolkit/telemetry/export"
	"go.uber.org/zap/zapcore"
	"k8s.io/apimachinery/pkg/runtime"
	clientgoscheme "k8s.io/client-go/kubernetes/scheme"
	_ "k8s.io/client-go/plugin/pkg/client/auth/gcp"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/log/zap"

	storageosv1 "github.com/storageos/api-manager/api/v1"
	"github.com/storageos/api-manager/controllers/fencer"
	nsdelete "github.com/storageos/api-manager/controllers/namespace-delete"
	nodedelete "github.com/storageos/api-manager/controllers/node-delete"
	nodelabel "github.com/storageos/api-manager/controllers/node-label"
	pvclabel "github.com/storageos/api-manager/controllers/pvc-label"
	"github.com/storageos/api-manager/internal/controllers/sharedvolume"
	"github.com/storageos/api-manager/internal/pkg/storageos"
	apimetrics "github.com/storageos/api-manager/internal/pkg/storageos/metrics"
	// +kubebuilder:scaffold:imports
)

const (
	// EventSourceName is added to Kubernetes events generated by the api
	// manager.  It can be used for filtering events.
	EventSourceName = "storageos-api-manager"
)

var (
	// ErrInvalidPollInterval is returned if the poll interval is invalid.
	ErrInvalidPollInterval = errors.New("--node-poll-interval must be at least 5s")
)

var (
	scheme   = runtime.NewScheme()
	setupLog = ctrl.Log.WithName("api-manager")
)

func init() {
	_ = clientgoscheme.AddToScheme(scheme)
	_ = storageosv1.AddToScheme(scheme)
	// +kubebuilder:scaffold:scheme
}

func main() {
	var loggerOpts zap.Options
	var metricsAddr string
	var enableLeaderElection bool
	var apiSecretPath string
	var apiEndpoint string
	var volumePollInterval time.Duration
	var nodePollInterval time.Duration
	var volumeExpiryInterval time.Duration
	var nodeExpiryInterval time.Duration
	var apiRefreshInterval time.Duration
	var apiRetryInterval time.Duration
	var k8sCreatePollInterval time.Duration
	var k8sCreateWaitDuration time.Duration
	var gcNamespaceDeleteInterval time.Duration
	var gcNodeDeleteInterval time.Duration
	var resyncNodeLabelInterval time.Duration
	var resyncPVCLabelInterval time.Duration
	var gcNamespaceDeleteDelay time.Duration
	var gcNodeDeleteDelay time.Duration
	var resyncNodeLabelDelay time.Duration
	var resyncPVCLabelDelay time.Duration
	var nsDeleteWorkers int
	var nodeDeleteWorkers int
	var nodeLabelSyncWorkers int
	var nodeFencerWorkers int
	var pvcLabelSyncWorkers int
	flag.StringVar(&metricsAddr, "metrics-addr", ":8080", "The address the metric endpoint binds to.")
	flag.BoolVar(&enableLeaderElection, "enable-leader-election", false,
		"Enable leader election for controller manager. "+
			"Enabling this will ensure there is only one active controller manager.")
	flag.StringVar(&apiSecretPath, "api-secret-path", "/etc/storageos/secrets/api", "Path where the StorageOS api secret is mounted.  The secret must have \"username\" and \"password\" set.")
	flag.StringVar(&apiEndpoint, "api-endpoint", "storageos", "The StorageOS api endpoint address.")
	flag.DurationVar(&volumePollInterval, "volume-poll-interval", 5*time.Second, "Frequency of StorageOS volume polling.")
	flag.DurationVar(&nodePollInterval, "node-poll-interval", 5*time.Second, "Frequency of StorageOS node polling.")
	flag.DurationVar(&volumeExpiryInterval, "volume-expiry-interval", time.Minute, "Frequency of cached StorageOS volume re-validation.")
	flag.DurationVar(&nodeExpiryInterval, "node-expiry-interval", time.Minute, "Frequency of cached StorageOS node re-validation.")
	flag.DurationVar(&apiRefreshInterval, "api-refresh-interval", time.Minute, "Frequency of StorageOS api authentication token refresh.")
	flag.DurationVar(&apiRetryInterval, "api-retry-interval", 5*time.Second, "Frequency of StorageOS api retries on failure.")
	flag.DurationVar(&k8sCreatePollInterval, "k8s-create-poll-interval", 1*time.Second, "Frequency of Kubernetes api polling for new objects to appear once created.")
	flag.DurationVar(&k8sCreateWaitDuration, "k8s-create-wait-duration", 20*time.Second, "Maximum time to wait for new Kubernetes objects to appear.")
	flag.DurationVar(&gcNamespaceDeleteInterval, "namespace-delete-gc-interval", 1*time.Hour, "Frequency of namespace garbage collection.")
	flag.DurationVar(&gcNodeDeleteInterval, "node-delete-gc-interval", 1*time.Hour, "Frequency of node garbage collection.")
	flag.DurationVar(&resyncNodeLabelInterval, "node-label-resync-interval", 1*time.Hour, "Frequency of node label resync.")
	flag.DurationVar(&resyncPVCLabelInterval, "pvc-label-resync-interval", 1*time.Hour, "Frequency of PVC label resync.")
	flag.DurationVar(&gcNamespaceDeleteDelay, "namespace-delete-gc-delay", 20*time.Second, "Startup delay of initial namespace garbage collection.")
	flag.DurationVar(&gcNodeDeleteDelay, "node-delete-gc-delay", 30*time.Second, "Startup delay of initial node garbage collection.")
	flag.DurationVar(&resyncNodeLabelDelay, "node-label-resync-delay", 10*time.Second, "Startup delay of initial node label resync.")
	flag.DurationVar(&resyncPVCLabelDelay, "pvc-label-resync-delay", 5*time.Second, "Startup delay of initial PVC label resync.")
	flag.IntVar(&nodeFencerWorkers, "node-fencer-workers", 1, "Maximum concurrent node fencing operations.")
	flag.IntVar(&nodeDeleteWorkers, "node-delete-workers", 5, "Maximum concurrent node delete operations.")
	flag.IntVar(&nsDeleteWorkers, "namespace-delete-workers", 5, "Maximum concurrent namespace delete operations.")
	flag.IntVar(&nodeLabelSyncWorkers, "node-label-sync-workers", 5, "Maximum concurrent node label sync operations.")
	flag.IntVar(&pvcLabelSyncWorkers, "pvc-label-sync-workers", 5, "Maximum concurrent PVC label sync operations.")

	loggerOpts.BindFlags(flag.CommandLine)
	flag.Parse()

	// Validation
	// TODO(sc): Add other validation.
	//
	// Poll interval must be at least 5 seconds.
	if nodeExpiryInterval < 5*time.Second {
		fatal(ErrInvalidPollInterval, "exiting")
	}

	f := func(ec *zapcore.EncoderConfig) {
		ec.TimeKey = "timestamp"
		ec.EncodeTime = zapcore.RFC3339NanoTimeEncoder
	}
	encoderOpts := func(o *zap.Options) {
		o.EncoderConfigOptions = append(o.EncoderConfigOptions, f)
	}
	ctrl.SetLogger(zap.New(zap.UseFlagOptions(&loggerOpts), zap.StacktraceLevel(zapcore.PanicLevel), encoderOpts))

	// Setup telemetry.
	telemetryShutdown, err := export.InstallJaegerExporter("api-manager")
	if err != nil {
		fatal(err, "unable to setup telemetry exporter")
	}
	defer telemetryShutdown()

	// Block startup until there is a working StorageOS API connection.  Unless
	// we loop here, we'll get a number of failures on cold cluster start as it
	// takes longer for the api to be ready than the api-manager to start.
	var api *storageos.Client
	for {
		username, password, err := storageos.ReadCredsFromMountedSecret(apiSecretPath)
		if err != nil {
			setupLog.Info(fmt.Sprintf("unable to read storageos api secret, retrying in %s", apiRetryInterval), "msg", err)
			apimetrics.Errors.Increment("setup", err)
			time.Sleep(apiRetryInterval)
			continue
		}
		api, err = storageos.NewTracedClient(username, password, apiEndpoint)
		if err == nil {
			apimetrics.Errors.Increment("setup", nil)
			break
		}
		setupLog.Info(fmt.Sprintf("unable to connect to storageos api, retrying in %s", apiRetryInterval), "msg", err)
		apimetrics.Errors.Increment("setup", err)
		time.Sleep(apiRetryInterval)
	}
	setupLog.Info("connected to the storageos api", "api-endpoint", apiEndpoint)

	// Only attempt to grab leader lock once we have an API connection.
	mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{
		Scheme:             scheme,
		MetricsBindAddress: metricsAddr,
		Port:               9443,
		LeaderElection:     enableLeaderElection,
		LeaderElectionID:   "d73494fd.storageos.com",
	})
	if err != nil {
		fatal(err, "unable to start manager")
	}

	// +kubebuilder:scaffold:builder

	// Events sent on apiReset channel will trigger the api client to re-initialise.
	apiReset := make(chan struct{})

	// Parent context will be closed on interrupt or sigterm.
	ctx, cancel := context.WithCancel(ctrl.SetupSignalHandler())
	defer cancel()

	// Goroutine to handle api credential refreshes and client reconnects
	// whenever events are received on the apiReset channel.
	go func() {
		err := api.Refresh(ctx, apiSecretPath, apiEndpoint, apiReset, apiRefreshInterval, apimetrics.Errors, setupLog)
		fatal(err, "api token refresh stopped")
	}()

	// Register controllers with controller manager.
	setupLog.Info("starting shared volume controller ")
	if err := sharedvolume.NewReconciler(api, apiReset, mgr.GetClient(), volumePollInterval, volumeExpiryInterval, k8sCreatePollInterval, k8sCreateWaitDuration, mgr.GetEventRecorderFor(EventSourceName)).SetupWithManager(mgr); err != nil {
		fatal(err, "failed to register shared volume reconciler")
	}

	setupLog.Info("starting pvc label sync controller ")
	if err := pvclabel.NewReconciler(api, mgr.GetClient(), resyncPVCLabelDelay, resyncPVCLabelInterval).SetupWithManager(mgr, pvcLabelSyncWorkers); err != nil {
		fatal(err, "failed to register pvc label reconciler")
	}
	setupLog.Info("starting node label sync controller ")
	if err := nodelabel.NewReconciler(api, mgr.GetClient(), resyncNodeLabelDelay, resyncNodeLabelInterval).SetupWithManager(mgr, nodeLabelSyncWorkers); err != nil {
		fatal(err, "failed to register node label reconciler")
	}
	setupLog.Info("starting node delete controller")
	if err := nodedelete.NewReconciler(api, mgr.GetClient(), gcNodeDeleteDelay, gcNodeDeleteInterval).SetupWithManager(mgr, nodeDeleteWorkers); err != nil {
		fatal(err, "failed to register node delete reconciler")
	}
	setupLog.Info("starting namespace delete controller")
	if err := nsdelete.NewReconciler(api, mgr.GetClient(), gcNamespaceDeleteDelay, gcNamespaceDeleteInterval).SetupWithManager(mgr, nsDeleteWorkers); err != nil {
		fatal(err, "failed to register namespace delete reconciler")
	}
	setupLog.Info("starting node fencing controller")
	if err := fencer.NewReconciler(api, apiReset, mgr.GetClient(), nodePollInterval, nodeExpiryInterval).SetupWithManager(ctx, mgr, nodeFencerWorkers); err != nil {
		fatal(err, "failed to register node fencing reconciler")
	}

	setupLog.Info("starting manager")
	if err := mgr.Start(ctx); err != nil {
		fatal(err, "failed to start manager")
	}
	setupLog.Info("shutdown complete")
}

func fatal(err error, msg string) {
	setupLog.Error(err, msg)
	os.Exit(1)
}
